---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---
Welcome to my website! I am a final-year PhD candidate in the Operations Research Center at MIT where I am advised by Professor Rahul Mazumder. My research lies in the intersection of statistical machine learning and discrete optimization, and I focus on developing efficient and explainable algorithms for data science and ML. I am also interested in developing interpretable ML methods for healthcare and public policy.

Prior to graduate school, I was a Data and Applied Scientist at Microsoft where I worked on online advertising and I am originally from the San Francisco Bay Area.


**I am on the 2025â€“2026 academic job market!**


Please find my CV [here](files/cvbrian.pdf).



<h2 style="margin-bottom: 0.25em; border-bottom: none; box-shadow: none;">Selected Awards</h2>
<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">
- Invited to the 2025 ISyE-MS&E-IOE Rising Stars Workshop 
- 2025 American Statistical Association Statistical Computing Section Best Student Paper Winner
- 2024 INFORMS Data Mining Society Best Student Paper Competition 1st Place

<h2 style="margin-bottom: 0.25em; border-bottom: none; box-shadow: none;">Working Papers</h2>
<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">

<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/tree_prompt.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      TreePrompt: Distilling Boosted Tree Ensembles for In-Context Learning in Large Language Models, 2025.
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li>Preliminary version to appear in <em>The First Structured Knowledge for Large Language Models Workshop (KDD 2025)</em></li>
    </ul>
  </div>

</div>



<h2 style="margin-bottom: 0.25em; border-bottom: none; box-shadow: none;">Under Review</h2>
<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">

<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/depth_prune.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives, 2025, 
      <a href="https://arxiv.org/abs/2506.20114">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong>, Rahul Mazumder, and Peter Radchenko</li>
      <li>Submitted to <em>Journal of the American Statistical Association (JASA)</em></li>
    </ul>
  </div>

</div>

<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">


<!-- - **B. Liu** and R. Mazumder. Locally Transparent Rule Sets for Explainable Machine Learning, 2025. Submitted to Operations Research. -->

<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/lots.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      Locally Transparent Rule Sets for Explainable Machine Learning, 2025.
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li>Submitted to <em>Operations Research</em></li>
    </ul>
  </div>

</div>




<h2 style="margin-bottom: 0.25em; border-bottom: none; box-shadow: none;">Publications</h2>
<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">




<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/rf_jmlr.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests, 2025, 
      <a href="https://arxiv.org/abs/2402.12668">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li>To appear in <em>Journal of Machine Learning Research (JMLR)</em></li>
    </ul>
  </div>

</div>

<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">

<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/moss1.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      MOSS: Multi-Objective Optimization for Stable Rule Sets, 2025,
      <a href="https://www.arxiv.org/abs/2506.08030">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li> <em>31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em></li>
      <li style="list-style-type: none; margin-left: -1em; display: flex; align-items: flex-start;">
  <span style="color: #b30000; margin-right: 0.5em;">ðŸ“Œ</span>
  <span style="color: #b30000;">2024 INFORMS Data Mining Society Best Student Paper Competition 1st Place.</span>
</li>

    </ul>
  </div>

</div> 

<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">


<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/fast2.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      FASTopt: An Optimization Framework for Fast Additive Segmentation, 2024,
      <a href="https://arxiv.org/abs/2402.12630">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li> <em>30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em></li>
      <li style="list-style-type: none; margin-left: -1em; display: flex; align-items: flex-start;">
  <span style="color: #b30000; margin-right: 0.5em;">ðŸ“Œ</span>
  <span style="color: #b30000;">2025 American Statistical Association Statistical Computing Student Paper Competition Winner.</span>
</li>

    </ul>
  </div>

</div>

<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">


<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/fire1.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      FIRE: An Optimization Framework for Fast Interpretable Rule Extraction, 2023,
      <a href="https://arxiv.org/abs/2306.07432">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li> <em>29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em></li>
    </ul>
  </div>

</div>


<hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">


<div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/forestprune.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      ForestPrune: Compact Depth-Pruned Tree Ensembles, 2023,
      <a href="https://arxiv.org/pdf/2206.00128">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong> and Rahul Mazumder</li>
      <li> <em>26th International Conference on Artificial Intelligence and Statistics (AISTATS)</em></li>
    </ul>
  </div>

</div>

  <hr style="border: none; border-top: 1px solid #ccc; margin: 2em 0;">

  <div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/controlburn.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      ControlBurn: Feature Selection by Sparse Forests, 2021,
      <a href="https://arxiv.org/abs/2107.00219">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong>, Miaolan Xie, and Madeleine Udell</li>
      <li> <em>27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em></li>
    </ul>
  </div>

</div>

<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">



  <div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/ijaa.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      Modeling the Risk of In-Person Instruction During the COVID-19 Pandemic, 2024,
      <a href="https://arxiv.org/pdf/2310.04563">arXiv.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li><strong>Brian Liu</strong><sup>*</sup>, Yujia Zhang<sup>*</sup>, Shane Henderson, David Shmoys, and Peter Frazier</li>
      <li> <em>INFORMS Journal of Applied Analytics</em></li>
    </ul>
  </div>

</div>


<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">


  <div style="display: flex; align-items: flex-start; margin-bottom: 2em;">

  <!-- Left: Image -->
  <div style="flex: 0 0 250px; margin-right: 25px;">
    <img src="images/pnas.png" alt="Paper Figure" style="width: 250px; border-radius: 8px;">
  </div>

  <!-- Right: Text without outer bullet -->
  <div>
    <p style="margin: 0;">
      Modeling for COVID-19 College Reopening Decisions: Cornell, A Case Study, 2022,
      <a href="https://www.pnas.org/doi/10.1073/pnas.2112532119">paper.</a>
    </p>
    <ul style="list-style-type: circle; margin-top: 4px;">
      <li>Peter Frazier, J. Massey Cashore, Ning Duan, Shane G. Henderson, Alyf Janmohamed, <strong>Brian Liu</strong> David B. Shmoys, Jiayue Wan, and Yujia Zhang</li>
      <li> <em>Proceedings of the National Academy of Sciences</em></li>
    </ul>
  </div>

</div>




<h2 style="margin-bottom: 0.25em; border-bottom: none; box-shadow: none;">Talks</h2>
<hr style="border: none; border-top: 1px solid #ccc; margin: 0.5em 0 2em;">

- MIT Sloan Health Systems Initiative Annual Workshop, October 2024
  - Interpretable Machine Learning Methods for Predicting Telemental Health Outcomes

- INFORMS Annual Meeting, October 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- International Symposium on Mathematical Programming, July 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- US Census Bureau Center for Statistical Research and Methodology, July 2024
  - Making Tree Ensembles Interpretable

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2023
  - Fast Interpretable Rule Extraction	

- INFORMS Annual Meeting, October 2022
  - Depth-Pruning Tree Ensembles

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2021
  - Feature Selection with Sparse Forests




