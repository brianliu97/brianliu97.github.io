---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---
Welcome to my website! I am a final-year PhD candidate in the Operations Research Center at MIT where I am advised by Professor Rahul Mazumder. My research lies in the intersection of statistical machine learning and discrete optimization, and I focus on developing efficient and explainable algorithms for data science and ML. I am also interested in developing interpretable ML methods for healthcare and public policy.

Prior to graduate school, I was a Data and Applied Scientist at Microsoft where I worked on online advertising and I am originally from the San Francisco Bay Area.

Please find my CV [here](files/cvbrian.pdf).

## Selected Honors and Awards
- Invited to the 2025 ISyE-MS&E-IOE Rising Stars Workshop 
- 2025 American Statistical Association Statistical Computing Section Best Student Paper Winner
- 2024 INFORMS Data Mining Society Best Student Paper Competition 1st Place

## Publications

### Under Review

- **B. Liu**, R. Mazumder, and P. Radchenko. Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives, https://arxiv.org/abs/2506.20114, 2025. Submitted to Journal of the American Statistical Association.

- **B. Liu** and R. Mazumder. Locally Transparent Rule Sets for Explainable Machine Learning, 2025. Submitted to Operations Research.

- **B. Liu**  and R. Mazumder. Randomization Can Reduce Both Bias and Variance: A Case Study in Random Forests, arxiv.org/abs/2402.12668, 2024. R&R at Journal of Machine Learning Research (JMLR).

### Published Works

- **B. Liu**  and R. Mazumder. MOSS: Multi-Objective Optimization for Stable Rule Sets. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2025.
  - 2024 INFORMS Data Mining Society Best Student Paper Competition 1st Place.

- **B. Liu**  and R. Mazumder. FASTopt: An Optimization Framework for Fast Additive Segmentation. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2024.
  - 2025 American Statistical Association Statistical Computing Student Paper Competition Winner.

- **B. Liu**  and R. Mazumder. FIRE: An Optimization Framework for Fast Interpretable Rule Extraction. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2023.
  
- **B. Liu**  and R. Mazumder. ForestPrune: Compact Depth-Pruned Tree Ensembles. In Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS), 2023.
  
- **B. Liu** , M. Xie, and M. Udell. ControlBurn: Feature Selection by Sparse Forests. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2021.

- **B. Liu\***, Y. Zhang\*, S. Henderson, D. Shmoys, P. Frazier. Modeling the risk of in-person instruction during the COVID-19 pandemic, INFORMS Journal of Applied Analytics, 2024.
  
- P. Frazier, J. M. Cashore, N. Duan, S. Henderson, A. Janmohamed, **B. Liu** , D. Shmoys, J. Wan, Y. Zhang.
Modeling for COVID-19 College Reopening Decisions: Cornell, A Case Study. Proceedings of the National Academy of Sciences.



## Talks

- MIT Sloan Health Systems Initiative Annual Workshop, October 2024
  - Interpretable Machine Learning Methods for Predicting Telemental Health Outcomes

- INFORMS Annual Meeting, October 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- International Symposium on Mathematical Programming, July 2024
  - An Optimization Framework for Fast Additive Segmentation in Transparent ML	

- US Census Bureau Center for Statistical Research and Methodology, July 2024
  - Making Tree Ensembles Interpretable

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2023
  - Fast Interpretable Rule Extraction	

- INFORMS Annual Meeting, October 2022
  - Depth-Pruning Tree Ensembles

- ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, August 2021
  - Feature Selection with Sparse Forests




